<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="https://www.w3.org/1999/xhtml">
<head>
<meta name="google-site-verification" content="BYTiR470kqE-73VMqF7Lzdf2VC_Jsy26AOw7V80Vzd4" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<!-- TemplateBeginEditable name="doctitle" -->
<title>Kangxue Yin's Homepage</title>
<!-- TemplateEndEditable -->
<!-- TemplateBeginEditable name="head" -->
<!-- TemplateEndEditable -->
<style type="text/css">
    <!--
	.STYLE2 {	font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
				font-size: 11pt;
	}
	.STYLE10 {	font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
				font-size: 10pt;
	}
	.STYLE3 {	font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
				font-size: 13pt;
	}
    .style5
    {
        height: 108px;
        width: 23px;
    }
    .style22
    {
        height: 70px;
    }
	
    .style32
    {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-size: 24pt;
    }
	
    .style33
    {
		font-family: Simsun, "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-size: 16pt;
    }
	a, a:visited{
     color: blue;
	 text-decoration: none;
	}
	
    .crop img {
        width: 243px;
        height: 137px;
		margin-left: -50px;
		margin-right: -50px;
    }
    img.animated-gif{
      width: 200px;
      height: auto;
    }
    img.animated-gif_2{
      width: 170px;
      height: auto;
    }
    -->
</style>
</head>
<body  bgcolor="#FFFFFF"   >
        		 
<!--

	&nbsp;<img src="bar.jpg" 
	style="height: 5px; width: 1310px; padding-bottom: 0px; margin-left: 0px; margin-bottom: 1px;" 
	align="center"  />
-->

<table width="1024" border="0" cellpadding="0" cellspacing="0" style="float:middle; margin-left:10px; width: 1024px">
  <!--DWLayoutTable-->
  
  
 <!-- photo and name -->
<tr>  
    <td class="style5" colspan="1" align="center"></td>
	
    <td colspan="1" align="center" style="width:171px" >
        <a href="fullphoto.jpg">
		<img src="photo.jpg"  style="height: 204px; width: 171px; padding-bottom: 0px; margin-right: 15px;"  align="center"  />
		</a>
	</td>
	
    <td colspan="4" valign="top" >
		
		<br>	
		<p class="STYLE10">
			<br><br>
			<span class="style32"><strong> Kangxue Yin</strong></span>
			<audio id="player"> <source src="pronounce.mp3" type='audio/mpeg'  preload="auto" ></audio>
			<input type="image"  src="images/pron.png" onclick="document.getElementById('player').play()"  style="height: 20px; width: 20px" />
			<!--
			<img src="name.png"  style="height: 30px; width: 71px; padding-bottom: 0px; margin-left: 0px;"  align="center" />
			
			<br>	
			<span class="style33">尹康学</span>	
			-->
			<br>
		</p>

	
        <p class="STYLE2">			
			Senior Research Scientist,
			<br>			
			NVIDIA, Toronto, Canada
			<br><br>
			kangxue.yin [at] gmail [dot] com
			<!-- 
			<br><br>			
			<a href="https://scholar.google.com/citations?user=1YasCXcAAAAJ&hl=en" style="text-decoration: none">Google Scholar</a> ·
			<a href="https://www.linkedin.com/in/kxyin/" style="text-decoration: none">LinkedIn</a>
			-->
			<br><br>	
			
		</p>
	</td> 
</tr>
    
<!-- self-intro -->
<tr>
  
	<!-- rowspan needs to be increased if the rows of the table grows bigger than 100 -->
    <td rowspan="100" colspan="1" class="style5">&nbsp;&nbsp;</td>  
    <td style="height: 80px;" colspan="5" valign="top" >    

	<p class="STYLE2">
    <!--<strong>I am looking for interns!</strong> Interested candidates can send their resumes to me directly.

    <br />
    <br />
	-->

    Bio: 
    I am a senior research scientist at <a href="https://research.nvidia.com/labs/toronto-ai/" style="text-decoration: none">NVIDIA Toronto AI lab</a>. I work on AI-based 3D content creation, with applications in artists' tools and self-driving simulation.
    Before joining NVIDIA, I received my Ph.D. degree in the year 2020  from <a href="https://www.sfu.ca/" style="text-decoration: none">Simon Fraser University</a> where I worked in the 
	<a href="https://gruvi.cs.sfu.ca/" style="text-decoration: none">GrUVi lab</a>  under the supervision of 
	Prof. <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao (Richard) Zhang</a>.   I also worked with
	Prof. <a href="https://vcc.tech/~huihuang"  style="text-decoration: none">Hui Huang</a> and  
	Prof. <a href="https://danielcohenor.com" style="text-decoration: none">Daniel Cohen-Or</a> who were on my supervisory committee as well.   
	Before joining SFU in the year 2015, I worked at Shenzhen Institutes of Advanced Technology (<a href="http://www.siat.cas.cn/" style="text-decoration: none">SIAT</a>), Chinese Academy of Sciences (CAS).
	I received my B.Eng. degree from <a href="https://en.wikipedia.org/wiki/Chang%27an_University" style="text-decoration: none">Chang'an University</a> in the year 2012.
	</p>					
	
    <p class="STYLE3"><strong> Publications</strong></p>
	  
    </td>
</tr>



<!-- publication -->


<!-- 
<tr>
	<td valign="middle" colspan="1"  ><strong>2021</strong>
	</td>	
	<td colspan="5" valign="middle" class="style22"></td>
</tr>
-->
<tr>

    <td valign="middle" align="center" > <a href="images/nfldm.mp4"> 
    	<video alt="hpp" style="border-style: none" width="185" controls muted loop autoplay><source src="images/nfldm.mp4" type="video/mp4"></video></a><br /><br />
	</td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2">
    	<strong>NeuralField-LDM: Scene Generation with Hierarchical Latent Diffusion Models</strong>. <br />
    	Seung Wook Kim<sup>*</sup>, Bradley Brown<sup>*</sup>,  <u>Kangxue Yin</u>, Karsten Kreis, Katja Schwarz, Daiqing Li, Robin Rombach, Antonio Torralba, Sanja Fidler <br />
		CVPR, 2023<br />
		[<a href="https://arxiv.org/abs/2304.09787">paper</a>][<a href="https://research.nvidia.com/labs/toronto-ai/NFLDM/">project page</a>]
		</span><br /><br />
	</td>
</tr>



<tr>

    <td valign="middle" align="center" > <a href="https://nv-tlabs.github.io/GET3D/assets/teaser-rotate.mp4"> <img src="images/get3d.jpg" alt="" width="187" height="105" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images</strong>. <br />
	Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, <u>Kangxue Yin</u>,  Daiqing Li, Or Litany, Zan Gojcic, Sanja Fidler<br />
	NeurIPS, 2022<br />
	[<a href="https://arxiv.org/pdf/2209.11163.pdf">paper</a>][<a href="https://nv-tlabs.github.io/GET3D/">project page</a>]
	</span>
	</td>
</tr>

<tr>

    <td valign="middle" align="center" > <a href="images/mvdecor.png"> <img src="images/mvdecor.png" alt="" width="150" height="150" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>MvDeCor: Multi-view Dense Correspondence Learning for Fine-grained 3D Segmentation</strong>. <br />
	Gopal Sharma, <u>Kangxue Yin</u>, Subhransu Maji, Evangelos Kalogerakis, Or Litany, Sanja Fidler<br />
	ECCV, 2022<br />
	[<a href="https://arxiv.org/pdf/2208.08580.pdf">paper</a>][<a href="https://nv-tlabs.github.io/MvDeCor/">project page</a>]
	</span>
	</td>
</tr>


<tr>

    <td valign="middle" align="center" > <a href="images/auv_net_teaser.jpg"> <img src="images/auv_net_teaser.jpg" alt="" width="170" height="170" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>AUV-Net: Learning Aligned UV Maps for Texture Transfer and Synthesis</strong>. <br />
	Zhiqin Chen, <u>Kangxue Yin</u>,  Sanja Fidler<br />
	CVPR, 2022<br />
	[<a href="https://arxiv.org/abs/2204.03105">paper</a>][<a href="https://nv-tlabs.github.io/AUV-NET/">project page</a>]
	</span>
	</td>
</tr>






<tr>

    <td valign="middle" > <a href="images/DMTET.png"> <img src="images/DMTET.png" alt="" width="187" height="115" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis</strong>. <br />
	Tianchang Shen, Jun Gao, <u>Kangxue Yin</u>, Ming-Yu Liu, Sanja Fidler<br />
	NeurIPS, 2021<br />
	[<a href="https://nv-tlabs.github.io/DMTet/assets/dmtet.pdf">paper</a>][<a href="https://nv-tlabs.github.io/DMTet/">project page</a>]
	</span>
	</td>
</tr>


<tr>
    <td valign="middle" >	            
    <br /><a href="images/cow-to-dog.gif"><img class="animated-gif" src="images/cow-to-dog.gif"></a>
    <br />
	</td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>3DStyleNet: Creating 3D Shapes with Geometric and Texture Style Variations</strong>. <br />
	<u>Kangxue Yin</u>, Jun Gao, Maria Shugrina, Sameh Khamis, Sanja Fidler<br />
	ICCV 2021 (oral)<br />
	[<a href="https://nv-tlabs.github.io/3DStyleNet/assets/3dstyle-paper.pdf">paper</a>][<a href="https://nv-tlabs.github.io/3DStyleNet/">project page</a>]
	</span>
	</td>
</tr>


<tr>
	<td valign="middle" >	
	<br /><a href="images/neuralLOD.jpg"><img class="animated-gif_2" src="images/neuralLOD.jpg"></a>
	<br /> <br />    
	</td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>Neural Geometric Level of Detail: Real-time Rendering with Implicit 3D Shapes</strong>. <br />
	Towaki Takikawa*, Joey Litalien*, <u>Kangxue Yin</u>, Karsten Kreis, Charles Loop, Derek Nowrouzezahrai, Alec Jacobson, Morgan McGuire, Sanja Fidler<br />
	CVPR 2021 (oral)<br />
	[<a href="https://nv-tlabs.github.io/nglod/assets/nglod.pdf">paper</a>][<a href="https://nv-tlabs.github.io/nglod/">project page</a>]
	</span>
	</td>
</tr>
 
<tr>
    <td valign="middle" > <a href="images/datasetgan.jpg"> <img src="images/datasetgan.jpg" alt="" width="187" height="108" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>DatasetGAN: Efficient labeled data factory with minimal human effort</strong>. <br />
	Yuxuan Zhang*, Huan Ling*, Jun Gao, <u>Kangxue Yin</u>, Jean-Francois Lafleche, Adela Barriuso, Antonio Torralba, Sanja Fidler<br />
	CVPR 2021 (oral)<br />
	[<a href="https://arxiv.org/abs/2104.06490">paper</a>][<a href="https://nv-tlabs.github.io/datasetGAN/">project page</a>]
	</span>
	</td>
</tr>


<!--
<tr>
	<td valign="middle" colspan="1"  ><strong>2020</strong>
	</td>	
	<td colspan="5" valign="middle" class="style22"></td>
</tr>
 -->
 

<tr>
    <td valign="middle" >	<a href="images/COALESCE.jpg">	<img src="images/COALESCE.jpg" alt="" width="187" height="137" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>COALESCE: Component Assembly by Learning to Synthesize Connections</strong>. <br />
	<u>Kangxue Yin</u>, Zhiqin Chen, Siddhartha Chaudhuri, Matthew Fisher, Vladimir Kim, Hao Zhang. <br />
	3DV 2020 (oral)<br />
	[<a href="https://arxiv.org/pdf/2008.01936.pdf">paper</a>][<a href="papers/COALESCE.mp4">video</a>][<a href="https://github.com/kangxue/COALESCE">data and code</a>]
	</span>
	</td>
</tr>

<tr>
    <td valign="middle" >	<a href="images/fame.png">	<img src="images/fame.png" alt="" width="187" height="137" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>FAME: 3D Shape Generation via Functionality-Aware Model Evolution</strong>. <br />
	Yanran Guan, Han Liu, Kun Liu, <u>Kangxue Yin</u>, Ruizhen Hu, Oliver van Kaick, Yan Zhang, Ersin Yumer, Nathan Carr, Radomir Mech, and Hao Zhang. <br />
	IEEE Transactions on Visualization and Computer Graphics(TVCG), 2020.<br />
	[<a href="https://arxiv.org/abs/2005.04464">paper</a>][<a href="https://github.com/IsaacGuan/FAME">code</a>]
	</span>
	</td>
</tr>
  
 
<!-- 
<tr>
    <td valign="middle" >
	<a href="images/sfulogo.png"><img src="images/sfulogo.png" width="187" height="120" /></a>
	</td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>Learning Shape-to-Shape Transformation.</strong><br />
	 <u>Kangxue Yin</u><br />
	 SFU Ph.D. Thesis, May 2020, <a href="PhD_Thesis_KangxueYin.pdf">PDF</a><br />
	 (A summary of my work on learning shape transform)
	</span>
	</td>
</tr>
  
-->

<!-- 
<tr>
	<td valign="middle" colspan="1"  ><strong>2019</strong>
	</td>	
	<td colspan="5" valign="middle" class="style22"></td>
</tr>
-->
  
<tr>
    <td valign="middle" >	<a href="images/logan.jpg">	<img src="images/logan.jpg" width="187" height="151" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>LOGAN: Unpaired Shape Transform in Latent Overcomplete Space.</strong><br />
	 <u>Kangxue Yin</u>, Zhiqin Chen, Hui Huang, Daniel Cohen-Or, Hao Zhang. <br />
	   ACM Transactions on Graphics 38(6)(Special Issue of SIGGRAPH ASIA 2019 ).<br />
		  
	 [<a href="https://arxiv.org/pdf/1903.10170.pdf">paper</a>] [<a href="papers/logan_supp.pdf">supp.</a>]  [<a href="papers/LOGAN-SIGA.pptx">slides</a>]
	 [<a href="https://kangxue.org/LOGAN.html">project page</a>] [<a href="https://drive.google.com/uc?id=1I0-3UfV7PP5DhTcPvI3BNQv9P1VIhmMF&export=download">data</a>] 
	 [<a href="https://github.com/kangxue/LOGAN/">code</a>]<br />
	 [selected by SIGGRAPH ASIA 2019 as <strong>one of six papers featured for press release</strong>]
	</span>
	</td>
 </tr>
  
  
  
<tr>
    <td valign="middle"  >
	<a href="images/imseg.png">
	<img src="images/imseg.png" width="187" height="118" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>BAE-NET: Branched Autoencoder for Shape Co-Segmentation. </strong><br />
	 Zhiqin Chen,  <u>Kangxue Yin</u>,  Matthew Fisher, Siddhartha Chaudhuri, Hao Zhang. <br />
	 Proc. of ICCV 2019<br />
	 [<a href="https://arxiv.org/pdf/1903.11228.pdf">paper</a>][<a href="papers/imseg_supp.pdf">supp.</a>][<a href="https://github.com/czq142857/BAE-NET">data + code</a>]<br />
	</span>
	</td>
 </tr>
  
  
<!--
<tr>
	<td valign="middle" colspan="1"  ><strong>2018</strong>
	</td>	
	<td colspan="5" valign="middle" class="style22"></td>
</tr>
-->

 <tr>
    <td valign="middle" >	<a href="images/p2p_intp3.jpg">	<img src="images/p2p_intp3.jpg" width="187" height="118" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>P2P-NET: Bidirectional Point Displacement Net for Shape Transform.  </strong><br />
	 <u>Kangxue Yin</u>, Hui Huang, Daniel Cohen-Or, Hao Zhang. <br />
	ACM Transactions on Graphics 37(4)(Special Issue of SIGGRAPH 2018 )<br />
	[<a href="https://arxiv.org/pdf/1803.09263.pdf">paper</a>][<a href="https://kangxue.org/P2P-NET.html">project page</a>][<a href="https://drive.google.com/u/0/uc?id=1kOh4lxoJtAqUx8L07vU2AG7CNnsFuME3&export=download">slides</a>][<a href="https://drive.google.com/u/0/uc?id=1ji7VirRLdZVLdIAbYN1i6ekZTtPq63Xf&export=download">fast-forward</a>][<a href="https://drive.google.com/uc?id=1LF0tmJERXXSsF8z8T23Sg87ilSCXOXdB&export=download">data(hdf5)</a>][<a href="https://drive.google.com/uc?id=1VUSJtcn_-lWER-_VkjWhlNMQvlpgjUEi&export=download">data(raw)</a>][<a href="https://github.com/kangxue/P2P-NET">code</a>]
	</span>
	</td>
</tr>
  

<tr>
    <td valign="middle" >
	<a href="images/2pose.jpg">
	<img src="images/2pose.jpg" width="187" height="169" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>A Sampling Approach to Generating Closely Interacting 3D Pose-pairs from 2D Annotations. </strong><br />
	  <u>Kangxue Yin</u>, Hui Huang, Edmond S. L. Ho, Hao Wang, Taku Komura, Daniel Cohen-Or, Hao Zhang. <br />
	IEEE Transactions on Visualization and Computer Graphics(TVCG), 2018.<br />
	[<a href="papers/pairint.pdf">paper</a>][<a href="papers/Occluded-Joint-Inference.mp4">video</a>][<a href="https://drive.google.com/uc?id=1ci7VL9eH1ka0-hPTMGQi1fwCDbLJJrpH&export=download">data</a>][<a href="papers/exe-demo.zip">exe-demo</a>]</span>
	</td>
</tr>
  
<!--
<tr>
	<td valign="middle" colspan="1"  ><strong>2013-2016</strong>
	</td>	
	<td colspan="5" valign="middle" class="style22"></td>
</tr>
-->

<tr>
    <td valign="middle" >
	<a href="images/plantCut.jpg">
	<span class="STYLE2"><img src="images/plantCut.jpg" width="187" height="146" /></a></span></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>Full 3D Plant Reconstruction via Intrusive Acquisition. </strong><br />
	 <u>Kangxue Yin</u>, Hui Huang, Pinxin Long, Alex Gaissinski, Minglun Gong, Andrei Sharf. <br />
	Computer Graphics Forum 35(1), 2016. <br />
	[<a href="papers/plantCut.pdf">paper</a>][<a href="https://vcc.szu.edu.cn/research/2016/PlantCut">project page</a>][<a href="https://drive.google.com/uc?id=1-O6_HibHOsZelxIY-y0WtWB7yHoAnGRH&export=download">data</a>]</span>
	</td>
</tr>


<tr>
    <td valign="middle" >
	<a href="images/gcd.jpg">
	<img src="images/gcd.jpg" width="187" height="146" /></a></td>
    <td colspan="5" valign="middle" class="style22"><p class="STYLE2"><strong>Generalized Cylinder Decomposition</strong>.<br />
      Yang Zhou,  <u>Kangxue Yin</u>, Hui Huang, Hao Zhang, Minglun Gong, Daniel Cohen-Or.<br />
      ACM Transactions on 
      Graphics 34(6)(Special Issue of SIGGRAPH ASIA 2015 ).<br />
    [<a href="papers/gcd.pdf">paper</a>][<a href="https://www.youtube.com/watch?v=eqvJeJ0ujMM">video</a>][<a href="http://vcc.szu.edu.cn/research/2015/GCD/">code + data + page</a>]</p>
	</td>
</tr> 

<tr>
    <td valign="middle" >	<a href="images/morfit.jpg">	<img src="images/morfit.jpg" alt="" width="187" height="148" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>Morfit: Interactive Surface Reconstruction from Incomplete Point Clouds with Curve-Driven Topology and Geometry Control</strong>. <br />
	 <u>Kangxue Yin</u>, Hui Huang, Hao Zhang, Minglun Gong, Daniel Cohen-or, Baoquan Chen.<br />
	ACM Transactions on 
	   Graphics 33(6)(Special Issue of SIGGRAPH ASIA 2014 ).<br />
	[<a href="papers/morfit.pdf">paper</a>][<a href="https://vcc.szu.edu.cn/research/2014/Morfit">project page</a>][<a href="papers\Morfit_video.mp4">video</a>][<a href="https://drive.google.com/open?id=0B1yWc4B_DEqPa2k2VnpQSzlId1k">slides</a>][<a href="https://github.com/kangxue/Morfit">code + data</a>]</span>
	</td>
</tr>

<tr>
    <td valign="middle" >	<a href="images/telereg.jpg">	<img src="images/telereg.jpg" alt="" width="187" height="137" /></a></td>
    <td colspan="5" valign="middle" class="style22"><span class="STYLE2"><strong>&quot;Mind the Gap&quot;: Tele-Registration for 
        Structure-Driven Image Completion</strong>. <br />
	Hui Huang,  <u>Kangxue Yin</u>, Minglun Gong, Dani Lischinski, Daniel Cohen-Or, Uri Ascher, Baoquan Chen.<br />
		  ACM Transactions on Graphics 32(6)(Special Issue of SIGGRAPH ASIA 2013 ).<br />
	[<a href="papers/tele-reg.pdf">paper</a>][<a href="https://drive.google.com/open?id=0B1yWc4B_DEqPcFROclJHOVZENjA">slides</a>][<a href="https://github.com/kangxue/Tele-Registration">core code + data</a>]</span>
	</td>
</tr>
  
<!-- 
<tr>
    <td colspan="6" valign="left" >					
    <br> <br> <p class="STYLE3"><strong>Preprint:</strong></p> <br> 
	</td>
</tr>

   -->
  
<tr>
</tr>
  
<tr>   
  <td colspan="5" valign="top" class="style22"> 
  </td>  
</tr>

</table>
</body>
</html>
